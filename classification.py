# -*- coding: utf-8 -*-
"""Untitled55.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZxHiKvG9YApwIsDHNRGsiLZm6963lDvJ
"""

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd

dataset = pd.read_csv('Activity_sheet_final.csv')
dataset.head()

x = dataset.drop(['Response'], axis = 1)
y = dataset['Response']
y.head()

from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
y = le.fit_transform(y)
print(y)

from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 42)
print(x_train)
print(y_train)
print(x_test)

# Commented out IPython magic to ensure Python compatibility.
# %pip install mlxtend --upgrade

from mlxtend.feature_selection import SequentialFeatureSelector as sfs
from sklearn.linear_model import LinearRegression
from sklearn.naive_bayes import GaussianNB
lreg = LinearRegression()
sfs1 = sfs(lreg, k_features = 9, forward = True, verbose = 2, scoring ='roc_auc')
sfs1 = sfs1.fit(x_train, y_train)

feat_names = list(sfs1.k_feature_names_)
print(feat_names)
#feat_names = ['ATSC8c']

from imblearn.over_sampling import SMOTE
smote = SMOTE(random_state=42)
x_train_resampled, y_train_resampled = smote.fit_resample(x_train, y_train)

print(y_train_resampled)

new_train_data = x_train_resampled[feat_names]
#new_train_data = x_train[feat_names]
print(new_train_data)

from sklearn.neighbors import KNeighborsClassifier
classifier = KNeighborsClassifier()
classifier.fit(new_train_data, y_train)

from sklearn.linear_model import LogisticRegression
classifier = LogisticRegression(random_state = 42)
classifier.fit(new_train_data, y_train)

from sklearn.ensemble import RandomForestClassifier
classifier = RandomForestClassifier(random_state = 42)
classifier.fit(new_train_data, y_train)

from sklearn.svm import SVC
classifier = SVC(random_state = 42)
classifier.fit(new_train_data, y_train_resampled)

from sklearn.naive_bayes import GaussianNB
classifier = GaussianNB()
classifier.fit(new_train_data, y_train)

y_pred_train = classifier.predict(new_train_data)
from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score, roc_auc_score, balanced_accuracy_score
cm = confusion_matrix(y_train, y_pred_train)
print(cm)
accuracy = accuracy_score(y_train, y_pred_train)
f1_score = f1_score(y_train, y_pred_train)
precision = precision_score(y_train, y_pred_train)
recall = recall_score(y_train, y_pred_train)
roc_auc = roc_auc_score(y_train, y_pred_train)
balanced_accuracy = balanced_accuracy_score(y_train, y_pred_train)
print(accuracy)
print(f1_score)
print(precision)
print(recall)
print(roc_auc)
print(balanced_accuracy)

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
cm = confusion_matrix(y_train_resampled, y_pred_train, labels=classifier.classes_)
disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=classifier.classes_)
disp.plot()

from sklearn.model_selection import cross_val_score, StratifiedKFold

# Define your classifier (SVC in this case)
classifier = SVC(random_state=42)

# Define the cross-validation method (StratifiedKFold with 5 folds)
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

# Perform cross-validation and get accuracy scores
cv_scores = cross_val_score(classifier, new_train_data, y_train_resampled, cv=cv, scoring='recall')

# Print the cross-validation scores
print("Cross-Validation Scores:", cv_scores)

# Calculate and print the mean and standard deviation of the scores
mean_recall = cv_scores.mean()
print("Mean recall:", mean_recall)

import sklearn
sklearn.metrics.get_scorer_names()

new_test_data = x_test[feat_names]
print(new_test_data)
y_pred = classifier.predict(new_test_data)

from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score, roc_auc_score,balanced_accuracy_score
cm = confusion_matrix(y_test, y_pred)
print(cm)
accuracy = accuracy_score(y_test, y_pred)
f1_score = f1_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
roc_auc = roc_auc_score(y_test, y_pred)
balanced_accuracy = balanced_accuracy_score(y_test, y_pred)
print(accuracy)
print(f1_score)
print(precision)
print(recall)
print(roc_auc)
print(balanced_accuracy)

# Create a DataFrame with 'ID', 'Actual_Response' (y_test), and 'Predicted_Response' (y_pred)
result_df = pd.DataFrame({'ID': x_test['ID'], 'Actual_Response': y_test, 'Predicted_Response': y_pred})

# Print the result DataFrame
print(result_df)

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
cm = confusion_matrix(y_test, y_pred, labels=classifier.classes_)
disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=classifier.classes_)
disp.plot()

trainingset_resampled=pd.DataFrame(new_train_data)
trainingset_resampled.to_csv(r'trainingset_resampled.csv', index=True, header=True)

ext_data = pd.read_csv('pythoninput_final.csv')
print(ext_data)
SMILES = ext_data['SMILES']
ID = ext_data['ID']
# Make predictions using your trained SVM classifier
extdata_pred = classifier.predict(ext_data[feat_names])

# Create a new DataFrame to store SMILES, ChEMBL ID, and predictions
output_df = pd.DataFrame({'SMILES': SMILES, 'ID': ID, 'Predictions': extdata_pred})

print(output_df)

output_df = pd.DataFrame(output_df)
output_df.to_csv(r'output_df.csv', index=True, header=True)

#y-randomization

num_permutations = 200

for _ in range(num_permutations):
        # Shuffle the target variable 'y'
        y_shuffled = np.random.permutation(y_train_resampled)

# Fit the model with the shuffled 'y'
print(y_shuffled)
classifier.fit(new_train_data, y_shuffled)

y_pred_shuffled = classifier.predict(new_test_data)

from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score, roc_auc_score,balanced_accuracy_score
cm = confusion_matrix(y_test, y_pred_shuffled)
print(cm)
accuracy = accuracy_score(y_test, y_pred_shuffled)
f1_score = f1_score(y_test, y_pred_shuffled)
precision = precision_score(y_test, y_pred_shuffled)
recall = recall_score(y_test, y_pred_shuffled)
roc_auc = roc_auc_score(y_test, y_pred_shuffled)
balanced_accuracy = balanced_accuracy_score(y_test, y_pred_shuffled)
print(accuracy)
print(f1_score)
print(precision)
print(recall)
print(roc_auc)
print(balanced_accuracy)